# Отчет о проделанной работе

## Этапы работы

- **Подготовка изолированного окружения.** Я настроил `Docker`-образ, в котором будут
  изолированно тестироватьcя решения и собиратьcя проект. 
- **Автоматизация сборки.** Я разработал систему сборки на основе `CMake`, которая
  управляет компиляцией всех компонентов проекта: бейзлайнa и моего решения, тестов, бенчмарков и т.д.
- **Упрощение взаимодействия.** Для удобства работы с проектом я создал `Makefile`,
  предоставляющий единый интерфейс с простыми командами для запуска тестов,
  бенчмарков и сессий профилирования.
- **Тестирование корректности.** Для проверки корректности того,
  что мое решение работает также как бейзлайн, я подключил библиотеку
  `GoogleTest`.
- В процессе написания тестов даже получилось обнаружить баг с переполнением в бейзлане.
- **Разработка генератора тестовых данных.** Для дальнейшей работы я разработал
  механизм генерации тестов, которые соответствуют ограничениям из условий
  задачи. В последствии на основе этих тестов я оценивал производительность
  решений.
- **Анализ производительности.** Для объективного сравнения
  перфоманса решений я подключил `Google Benchmark`. Это позволило
  мне уже ориентируясь на метрики гораздо точнее рассуждать про 
  эффективность рассматриваемых оптимизаций.
- **Профилирование кода.** В дополнение к бенчмаркам, я добавил возможность анализа
  производительности с использованием `perf` внутри
  Docker-контейнера. Это дало инструмент для поиска ботлнеков в коде и
  определения дальнейших точек роста.
- **Быстрая сериализация.** Для ускорения тестирования я перенес сериализацию и
  парсинг входных файлов на `protobuf`. Это значительно снизило размер хранимых
  тестов и ускорило выполнение бенчмарков.
- В результате проделанной работы была создана полноценная и удобная
  инфраструктура, позволяющая эффективно вести разработку, гарантировать
  корректность кода и объективно оценивать его производительность.

## Баг в бейзлайне

Почти на любом сгененированном тесте в бейзлайне переполняется cur_result:

```cpp
cur_result += p->quantity * p->price;

```
Но если скастовать количество к `uint64_t`, чтобы вычисления происходили в корректном типе,
переполнения уже не происходит:

```cpp
cur_result += static_cast<uint64_t>(p->quantity) * p->price;
```

То же самое на пару строчек ниже в добавлении остатка от `shares`.

## Чем мое решение лучше предоставленного

В контесте мое решение сильно уступает бейзлайну. Я предполагаю, что это
связано с модальностью данных в используемом тесте, или конфигурацией кешей в
тестирующей системе. С помощью бенчмарков можно увидеть, что на случайном
корректном тесте **локально мое решение обгоняет бейзлайн на ~10%-15%** ~(34.5
против 39.0) в среднем по тестам. Это статистически значимый результат и он
довольно стабильно сохраняется между разными тестами. Через `perf` можно
установить причину.

### Baseline vs. Solution

| Metric | Baseline | Solution | Difference (B - S) | Change |
| :--- | :--- | :--- | :--- | :--- |
| **Execution Time (Google Benchmark)** | | | | |
| Mean Time (ms) | 39.1 | 34.0 | **+5.1** | `+15.00%` |
| **CPU Pipeline (Perf)** | | | | |
| cycles | 60.03 B | 59.42 B | **+0.61 B** | `+1.02%` |
| stalled-cycles-frontend | 1.82 B | 1.67 B | **+0.15 B** | `+8.98%` |
| instructions | 222.89 B | 220.75 B | **+2.14 B** | `+0.97%` |
| branches | 46.74 B | 46.83 B | **-0.09 B** | `-0.19%` |
| branch-misses | 87.42 M | 81.20 M | **+6.22 M** | `+7.66%` |
| **Cache & Memory (Perf)** | | | | |
| L1-dcache-loads | 71.19 B | 70.98 B | **+0.21 B** | `+0.29%` |
| L1-dcache-load-misses | 128.61 M | 137.15 M | **-8.54 M** | `-6.78%` |
| L1-icache-loads | 2.30 B | 2.23 B | **+0.08 B** | `+3.59%` |
| L1-icache-load-misses | 3.86 M | 3.93 M | **-0.07 M** | `-1.87%` |
| dTLB-loads | 5.08 M | 5.12 M | **-0.04 M** | `-0.78%` |
| dTLB-load-misses | 1.52 M | 1.62 M | **-0.10 M** | `-6.62%` |
| iTLB-loads | 43.75 K | 21.61 K | **+22.14 K** | `+102.45%` |
| iTLB-load-misses | 0.85 M | 0.86 M | **-0.01 M** | `-1.08%` |
| L1-dcache-prefetches | 92.76 M | 98.43 M | **-5.67 M** | `-6.11%` |

---

По метрикам решение выглядит хорошо. Помимо значимого прироста в скорости, можно отметить снижение в два раза `iTLB-loads`, то есть у нас сильно меньше стало серьезных промахов, а значит улучшилась локальность. В остальном все осталось примерно на том же уровне, однако решение проигрывает бейзлайну в онлайн контесте.

В своем коде я:
- Убрал создание булеанов - прибавляю налету буловые выражения. *(Чтобы компилятор мог использовать cmov и что-то похожее)*.
- Убрал шаблоны с итераторами и теперь двигаю чистые указатели. *(Честно-говоря, просто не понял зачем оно нужно)*.
- Убрал лишнее копирование из функции слияния - теперь я принимаю переменные сразу в аргументах функции. *(Скорее всего компилятор и сам это сделает, но тем не менее)*.
- Cократил перемещение цены и количества в одно копирование структуры. *(Вроде ничего не дает, но код выглядит почище)*.
- Заменил цикл с копированием ненулевых элементов из update на `std::copy_if` (немного улучшает метрики).

## Итоги

Мое решение корректнее бейзлайна (исправлен баг с переполнение) и на моей машине быстрее на ~10-15%, однако проигрывает бейзлайну на приватном тесте в контесте.

Как показывает `perf`, эта скорость достигнута ценой улучшения локальности кода.

*Все эксперименты можно воспроизвести на любой машине, достаточно развернуть `Docker`-образ с помощью докер файла.*
